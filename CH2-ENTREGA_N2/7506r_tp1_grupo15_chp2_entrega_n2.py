# -*- coding: utf-8 -*-
"""7506R_TP1_GRUPO15_CHP2_ENTREGA_N2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bsgO0AIY0Vai_YNWKNvwRD-kyU4PdtXS

# Imports y Preparacion del dataset
"""

import pandas as pd
import numpy as np
import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn as sk
import sklearn.preprocessing as skp
import scipy.stats as stats
import scipy as sc
from sklearn.feature_extraction import FeatureHasher
from sklearn.feature_selection import VarianceThreshold
from sklearn.impute import KNNImputer, SimpleImputer
from sklearn.linear_model import LinearRegression
from sklearn.metrics import confusion_matrix, classification_report

#joblib
#from joblib import dump, load
import joblib

# multivariado   
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from sklearn.neighbors import DistanceMetric

from sklearn import metrics

from sklearn.metrics import precision_score, recall_score, accuracy_score,f1_score#, precision_recall_curve, roc_curve,

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Datasets/hotels_train.csv') 
df_test = pd.read_csv('/content/drive/MyDrive/Datasets/hotels_test.csv')
df_test_original = df_test.copy()
df_original = df.copy()

"""
#Preprocesamiento"""

columnas = {"adr": "average_daily_rate", "arrival_date_year":"year", "arrival_date_month":"month", "arrival_date_day_of_month":"day"} #cambiar nombres a las categorias
df.rename(columns = columnas, inplace = True)
df = df.drop(columns=['arrival_date_week_number'])
#CAMBIO EL UNDEFINED A SC :)
df.loc[df.loc[:,"meal"]=='Undefined',"meal"]="SC"
#COUNTRY
df['country'] = df['country'].fillna("PRT")
paises_comunes = ['PRT','GBR','FRA','ESP','DEU','ITA','IRL', 'BRA', 'BEL', 'USA', 'NLD', 'CHE', 'CN', 'AUT', 'CHN', 'SWE', 'POL', 'RUS', 'ISR', 'NOR']
df.loc[~df.loc[:,"country"].isin(paises_comunes),"country"]="OTHER"
#TENEMOS QUE VER LOS 2 UNDEFINED 
df.drop(df[df['market_segment']=='Undefined'].index, axis='index',inplace=True)
df.drop(df[df['distribution_channel']=='Undefined'].index, axis='index',inplace=True)
#ROOM TYPES
room_type_populares = ["A", "D", "E", "F", "G"]
df.loc[~df.loc[:,"assigned_room_type"].isin(room_type_populares),"assigned_room_type"]="O"
df.loc[~df.loc[:,"reserved_room_type"].isin(room_type_populares),"reserved_room_type"]="O"
#ARRIVAL_DATE
months = {'January':1, 'February':2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7, 'August':8,'September':9, 'October':10,'November':11, 'December': 12 }
df.month = df.month.map(months)
arrivaldates = df.copy() 

date=arrivaldates.apply(lambda x: datetime.date(int(x['year']), x['month'], x['day']),axis=1)

date = pd.to_datetime(date)

df = df.drop(columns=['year', 'month', 'day'])

df.insert(0, 'arrival_date', date)

#DROP COMPANY
df= df.drop(columns=['company', 'reservation_status_date'])
#CHILDREN
df['children'] = df['children'].fillna(0.0)
df['children'] = df['children'].astype(int)
#AGENT
df['agent'] = df['agent'].fillna(9.0)
df['agent'] = df['agent'].astype(int)

#eliminamos el outlier porque una fila respecto a la gran cantidad de datos que tenemos no es relevante
df.drop(df[df['average_daily_rate']<0].index, axis='index',inplace=True)
df.drop(df[df['average_daily_rate']==0].index, axis='index',inplace=True)
#
df.drop(df[(df['babies']==0) & (df['adults']==0) & (df['children']==0)].index, axis='index',inplace=True)
df.drop(df[(df['babies']==0) & (df['adults']==0) & (df['children']==0)].index, axis='index',inplace=True)
#creamos una nueva col para verificar el tipo de habitacion
df['assigned_equals_reserved'] = np.where(df['assigned_room_type']== df['reserved_room_type'], True, False)
df['assigned_equals_reserved']=df['assigned_equals_reserved'].astype(int)
#TEMPORADA ALTA
temporada_alta = [1,6,7,8,12]
df['temporada_alta'] = pd.DatetimeIndex(df['arrival_date']).month.isin(temporada_alta)
df['temporada_alta'] = df['temporada_alta'] .astype(int)
#DUMMIES
dataset = df.copy()
dataset = pd.get_dummies(dataset, columns=["hotel","meal","deposit_type","customer_type","country"], drop_first=True)
dataset = pd.get_dummies(dataset, columns=["distribution_channel"], drop_first=True)
dataset = pd.get_dummies(dataset, columns=["market_segment"], drop_first=True)

df_test.rename(columns = columnas, inplace = True)
df_test = df_test.drop(columns=['arrival_date_week_number'])
#CAMBIO EL UNDEFINED A SC :)
df_test.loc[df_test.loc[:,"meal"]=='Undefined',"meal"]="SC"
#COUNTRY
df_test['country'] = df_test['country'].fillna("PRT")
df_test.loc[~df_test.loc[:,"country"].isin(paises_comunes),"country"]="OTHER"

#TENEMOS QUE VER LOS 2 UNDEFINED 
df_test.drop(df_test[df_test['market_segment']=='Undefined'].index, axis='index',inplace=True)
df_test.drop(df_test[df_test['distribution_channel']=='Undefined'].index, axis='index',inplace=True)
#ROOM TYPES
df_test.loc[~df_test.loc[:,"assigned_room_type"].isin(room_type_populares),"assigned_room_type"]="O"
df_test.loc[~df_test.loc[:,"reserved_room_type"].isin(room_type_populares),"reserved_room_type"]="O"
#ARRIVAL_DATE
df_test.month = df_test.month.map(months)
arrivaldates = df_test.copy()
date=arrivaldates.apply(lambda x: datetime.date(int(x['year']), x['month'], x['day']),axis=1)
date = pd.to_datetime(date)
df_test = df_test.drop(columns=['year', 'month', 'day'])
df_test.insert(0, 'arrival_date', date)
#DROP COMPANY
df_test= df_test.drop(columns=['company'])

#CHILDREN
df_test['children'] = df_test['children'].fillna(0.0)
df_test['children'] = df_test['children'].astype(int)
#AGENT
df_test['agent'] = df_test['agent'].fillna(9.0)
df_test['agent'] = df_test['agent'].astype(int)

#eliminamos el outlier porque una fila respecto a la gran cantidad de datos que tenemos no es relevante
df_test.drop(df_test[df_test['average_daily_rate']<0].index, axis='index',inplace=True)
df_test.drop(df_test[df_test['average_daily_rate']==0].index, axis='index',inplace=True)
#
df_test.drop(df_test[(df_test['babies']==0) & (df_test['adults']==0) & (df_test['children']==0)].index, axis='index',inplace=True)
df_test.drop(df_test[(df_test['babies']==0) & (df_test['adults']==0) & (df_test['children']==0)].index, axis='index',inplace=True)
#creamos una nueva col para verificar el tipo de habitacion
df_test['assigned_equals_reserved'] = np.where(df_test['assigned_room_type']== df_test['reserved_room_type'], True, False) 
df_test['assigned_equals_reserved']=df_test['assigned_equals_reserved'].astype(int)
#TEMPORADA_ALTA
df_test['temporada_alta'] = pd.DatetimeIndex(df_test['arrival_date']).month.isin(temporada_alta)
df_test['temporada_alta'] = df_test['temporada_alta'] .astype(int)

df_test = pd.get_dummies(df_test, columns=["hotel","meal","deposit_type","customer_type","country"], drop_first=True)
df_test = pd.get_dummies(df_test, columns=["distribution_channel"], drop_first=True)
df_test = pd.get_dummies(df_test, columns=["market_segment"], drop_first=True)

"""# CHECKPOINT 2

Aca arrancamos con arboles :)
"""

target='is_canceled'

#Verifico balanceo de clases
dataset[target].value_counts(normalize=True)*100

"""# Arbol de decision N1"""

features1= ['hotel_Resort Hotel','meal_FB','meal_HB','meal_SC','lead_time', 'adults', 'children', 'babies', 'previous_cancellations','days_in_waiting_list']

#Separo un set de Evaluacion 
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(dataset[features1].values, 
                                                    dataset[target].values, 
                                                    test_size=0.2,    #20% al conjunto de test 80/20
                                                    random_state=13,  #para poder reproducir el experimento
                                                    stratify=dataset[target].values) #estratificado para mantener proporcion 

#Verifico Cantidad de Datos en cada set
print('# Datos Entrenamiento: {}'.format(len(x_train)))
print('# Datos Prueba: {}'.format(len(x_test)))

#Verifico como quedaron balanceados
for split_name, split in zip(['% Positivos Entrenamiento','% Positivos Prueba'],[y_train,y_test]):
  print('{}: {:.3f}'.format(split_name,pd.Series(split).value_counts(normalize=True)[1]*100))

dataset.shape

##KFOLD CV Random Search para buscar el mejor arbol 
from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import make_scorer

#Cantidad de combinaciones que quiero porbar
n=30 

#Conjunto de parámetros que quiero usar 
params_grid = {'criterion':['gini','entropy'], #LE DOY POSIBLES CRITERIOS DE PARAMETROS 
               #'min_samples_leaf':list(range(1,10)),
               #'min_samples_split': list(range(2,20)),
               'ccp_alpha':np.linspace(0,0.005,n), #UN RANGO DE ALPHA(PODA) CON N CORTES
               'max_depth':list(range(1,8))} #RANGO DE PROFUNDIDAD
                
#Cantidad de splits para el Cross Validation
folds=20 

#Kfold estratificado
kfoldcv = StratifiedKFold(n_splits=folds)  

#Clasificador  
base_tree = DecisionTreeClassifier() 

#Metrica que quiero optimizar F1 Score
scorer_fn = make_scorer(sk.metrics.f1_score) 

#Random Search Cross Validation 
randomcv = RandomizedSearchCV(estimator=base_tree, 
                              param_distributions = params_grid,
                              scoring=scorer_fn, 
                              cv=kfoldcv,
                              n_iter=n) 

#Busco los hiperparamtros que optimizan F1 Score
randomcv.fit(x_train,y_train);

#Mejores hiperparametros del arbol 
print(randomcv.best_params_)
#Mejor métrica
print(randomcv.best_score_)

#Atributos considerados y su importancia
best_tree = randomcv.best_estimator_ 
feat_imps = best_tree.feature_importances_ 

for feat_imp,feat in sorted(zip(feat_imps,features1)): 
  if feat_imp>0:
    print('{}: {}'.format(feat,feat_imp))

#Creo el árbol con los mejores hiperparámetros
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_text

arbol=DecisionTreeClassifier().set_params(**randomcv.best_params_)

#Entreno el arbol en todo el set
arbol.fit(x_train,y_train) 

reglas = export_text(arbol, feature_names=list(features1)) #IMPRIMO TODAS LAS REGLAS
print(reglas)

from six import StringIO #IMPRIMO EL ARBOL
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
import matplotlib.pyplot as plt

dot_data = StringIO()
export_graphviz(arbol, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True,
                feature_names=features1,
                class_names=['good','bad'])

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png())

#Realizamos una predicción sobre el set de test
y_pred = arbol.predict(x_test)
#Valores Predichos
y_pred

print('correctas: ', np.sum(y_test == y_pred))
print('total: ', len(y_test))

accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
f1=f1_score(y_test,y_pred,)
precision=precision_score(y_test,y_pred)

print("Accuracy: "+str(accuracy)) 
print("Recall: "+str(recall))
print("Precision: "+str(precision))
print("f1 score: "+str(f1))

joblib.dump(arbol, 'arbol1.pkl')

"""# Arbol de decision N2"""

features2= ['lead_time','previous_cancellations','booking_changes','previous_bookings_not_canceled', 'stays_in_week_nights','days_in_waiting_list']

x_train, x_test, y_train, y_test = train_test_split(dataset[features2].values, 
                                                    dataset[target].values, 
                                                    test_size=0.2,    #20% al conjunto de test 80/20
                                                    random_state=13,  #para poder reproducir el experimento
                                                    stratify=dataset[target].values) #estratificado para mantener proporcion

#Verifico Cantidad de Datos en cada set
print('# Datos Entrenamiento: {}'.format(len(x_train)))
print('# Datos Prueba: {}'.format(len(x_test)))

#Verifico como quedaron balanceados
for split_name, split in zip(['% Positivos Entrenamiento','% Positivos Prueba'],[y_train,y_test]):
  print('{}: {:.3f}'.format(split_name,pd.Series(split).value_counts(normalize=True)[1]*100))

##KFOLD CV Random Search para buscar el mejor arbol (los mejores atributos, hiperparametros,etc)
from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import make_scorer

#Cantidad de combinaciones que quiero porbar
n=30 

#Conjunto de parámetros que quiero usar 
params_grid = {'criterion':['gini','entropy'], #LE DOY POSIBLES CRITERIOS DE PARAMETROS 
               #'min_samples_leaf':list(range(1,10)),
               #'min_samples_split': list(range(2,20)),
               'ccp_alpha':np.linspace(0.001,0.005,n), #UN RANGO DE ALPHA(PODA) CON N CORTES, AUNQUE PODIA SER UN N MAYOR A 10
               'max_depth':list(range(1,6))} #RANGO DE PROFUNDIDAD
                
#Cantidad de splits para el Cross Validation
folds=45 

#Kfold estratificado
kfoldcv = StratifiedKFold(n_splits=folds) 

#Clasificador ARMO MI CLASIFICADOR 
base_tree = DecisionTreeClassifier() 

#Metrica que quiero optimizar F1 Score
scorer_fn = make_scorer(sk.metrics.f1_score) 

#Random Search Cross Validation BUSCADOR RANDOM CON VALIDACION CRUZADA
randomcv = RandomizedSearchCV(estimator=base_tree, #CREO MI VALIDACION CRUZADA con busqueda random de hiperparametros RANDOM SEARCH
                              param_distributions = params_grid,
                              scoring=scorer_fn, #METRICA QUE QUUIERO OPTIMIZAR
                              cv=kfoldcv,
                              n_iter=n)  

#Busco los hiperparamtros que optimizan F1 Score
randomcv.fit(x_train,y_train);

#Mejores hiperparametros del arbol 
print(randomcv.best_params_)
#Mejor métrica
print(randomcv.best_score_)

#Atributos considerados y su importancia
best_tree = randomcv.best_estimator_ #ME DEVUELVE MI MEJOR ARBOL
feat_imps = best_tree.feature_importances_ #AL MEJOR ARBOL LE PIDO SUS MEJORES FEATURES

for feat_imp,feat in sorted(zip(feat_imps,features2)):
  if feat_imp>0:
    print('{}: {}'.format(feat,feat_imp))

"""# Arbol de decision N3"""

features3= ['lead_time','previous_cancellations','booking_changes', 'previous_bookings_not_canceled','days_in_waiting_list' ]

x_train, x_test, y_train, y_test = train_test_split(dataset[features3].values, 
                                                    dataset[target].values, 
                                                    test_size=0.2,    #20% al conjunto de test 80/20
                                                    random_state=13,  #para poder reproducir el experimento
                                                    stratify=dataset[target].values) #estratificado para mantener proporcion #QUEREMOS QUE SE RESPETE LA DIST DE LAS CLASES, APRENDER DE LAS 2 CLASES

#Verifico Cantidad de Datos en cada set
print('# Datos Entrenamiento: {}'.format(len(x_train)))
print('# Datos Prueba: {}'.format(len(x_test)))

#Verifico como quedaron balanceados
for split_name, split in zip(['% Positivos Entrenamiento','% Positivos Prueba'],[y_train,y_test]):
  print('{}: {:.3f}'.format(split_name,pd.Series(split).value_counts(normalize=True)[1]*100))

##KFOLD CV Random Search para buscar el mejor arbol (los mejores atributos, hiperparametros,etc)
from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV, GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import make_scorer

#Cantidad de combinaciones que quiero porbar
n=20 

#Conjunto de parámetros que quiero usar GRILLA DE PARAMETROS
params_grid = {'criterion':['gini','entropy'], #LE DOY POSIBLES CRITERIOS DE PARAMETROS 
               #'min_samples_leaf':list(range(1,10)),
               #'min_samples_split': list(range(2,20)),
               'ccp_alpha':np.linspace(0.001,0.005,n), #UN RANGO DE ALPHA(PODA) CON N CORTES, AUNQUE PODIA SER UN N MAYOR A 10
               'max_depth':list(range(2,12))} #RANGO DE PROFUNDIDAD
                
#Cantidad de splits para el Cross Validation
folds=25 

#Kfold estratificado
kfoldcv = StratifiedKFold(n_splits=folds)

#Clasificador ARMO MI CLASIFICADOR 
base_tree = DecisionTreeClassifier() 

#Metrica que quiero optimizar F1 Score
scorer_fn = make_scorer(sk.metrics.f1_score) #ACA DECIDO QUE MI MEJOR CONJUNTO SEA A BSAE DE MEDIR F1 SCORE 

#Random Search Cross Validation BUSCADOR RANDOM CON VALIDACION CRUZADA
randomcv = GridSearchCV(estimator=base_tree, #CREO MI VALIDACION CRUZADA con busqueda random de hiperparametros RANDOM SEARCH
                              param_grid = params_grid,
                              scoring=scorer_fn, #METRICA QUE QUUIERO OPTIMIZAR
                              cv=kfoldcv,
                              n_jobs=n) #LO TENER QUE HACER 10 VECES, PORQUE ES LA CANT DE HIPERPARAMETROS  

#Busco los hiperparamtros que optimizan F1 Score
randomcv.fit(x_train,y_train); #LO ENTRENO SOBRE MI DATASET DE ENTRENAMIENTO

#Mejores hiperparametros del arbol PROBASTE 10 DECIME CUAL FUE EL DE LA MEJOR METRICAS
print(randomcv.best_params_)
#Mejor métrica
print(randomcv.best_score_) #EL ARBOL QUE MEJOR PERFORMO TIENE ESTO, AL SER RANDOM, AL VOLVER A CORRER PUEDE QUE ME DEN OTROS, EN ESTE CASO F1, SI DA MUY BAJO PUEDO MODIFICAR MIS PARAMETRO

#Atributos considerados y su importancia
best_tree = randomcv.best_estimator_ #ME DEVUELVE MI MEJOR ARBOL
feat_imps = best_tree.feature_importances_ #AL MEJOR ARBOL LE PIDO SUS MEJORES FEATURES

for feat_imp,feat in sorted(zip(feat_imps,features3)): #ME DIJO CON EL ALCOHOL Y SULFATOS TE PUEDO ARMAR UN BUEN CLASIFICADOR (EL ALCOHOL TIENE BUENA CORRELACION CON EL TARGET LO VIMOS EN EL HEATMAP)
  if feat_imp>0:
    print('{}: {}'.format(feat,feat_imp))

#Creo el árbol con los mejores hiperparámetros
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_text

arbol=DecisionTreeClassifier().set_params(**randomcv.best_params_)

#Entreno el arbol en todo el set
arbol.fit(x_train,y_train) #LO ENTRENO CON TODO EL SET DE ENTRENAMIENTO

reglas = export_text(arbol, feature_names=list(features3)) #IMPRIMO TODAS LAS REGLAS
print(reglas)

from six import StringIO #IMPRIMO EL ARBOL
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
import matplotlib.pyplot as plt

dot_data = StringIO()
export_graphviz(arbol, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True,
                feature_names=features3,
                class_names=['good','bad'])

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png())

df_test.dtypes

prueba = df_test.copy()

filas_totales=df_test.shape[0]
print(df_test.isna().sum()/filas_totales*100)

prueba = df_test[['lead_time','previous_cancellations','booking_changes', 'previous_bookings_not_canceled', 'days_in_waiting_list' ]]

y_pred = arbol.predict(x_test)

accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
f1=f1_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)

print("Accuracy: "+str(accuracy)) 
print("Recall: "+str(recall))
print("Precision: "+str(precision))
print("f1 score: "+str(f1))

predicciones = arbol.predict(prueba)

predicciones

predicciones.size

df_test.shape

df_test.columns

df_submission = pd.DataFrame({'id':df_test['id'], 'is_canceled':predicciones})
df_submission.head()
df_submission.shape

"""#Arbol de decision N4"""

dataset.columns

features4= ['lead_time', 'stays_in_weekend_nights',
       'stays_in_week_nights', 'adults', 'children', 'babies',
       'is_repeated_guest',
       'previous_cancellations', 'previous_bookings_not_canceled','booking_changes',
        'days_in_waiting_list',
       'average_daily_rate', 'required_car_parking_spaces',
       'total_of_special_requests', 'hotel_Resort Hotel',
       'meal_FB', 'meal_HB', 'meal_SC']

x_train, x_test, y_train, y_test = train_test_split(dataset[features4].values, 
                                                    dataset[target].values, 
                                                    test_size=0.2,    #20% al conjunto de test 80/20
                                                    random_state=13,  #para poder reproducir el experimento
                                                    stratify=dataset[target].values) #estratificado para mantener proporcion #QUEREMOS QUE SE RESPETE LA DIST DE LAS CLASES, APRENDER DE LAS 2 CLASES

#Verifico Cantidad de Datos en cada set
print('# Datos Entrenamiento: {}'.format(len(x_train)))
print('# Datos Prueba: {}'.format(len(x_test)))

#Verifico como quedaron balanceados
for split_name, split in zip(['% Positivos Entrenamiento','% Positivos Prueba'],[y_train,y_test]):
  print('{}: {:.3f}'.format(split_name,pd.Series(split).value_counts(normalize=True)[1]*100))

##KFOLD CV Random Search para buscar el mejor arbol (los mejores atributos, hiperparametros,etc)
from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import make_scorer

#Cantidad de combinaciones que quiero porbar
n=30 #LE PIDO QUE ME ARME 20 COMB POR CADA SPLIT(ENTRENA 20 ARBOLES POR CADA SPLIT)

#Conjunto de parámetros que quiero usar GRILLA DE PARAMETROS
params_grid = {'criterion':['gini','entropy'], #LE DOY POSIBLES CRITERIOS DE PARAMETROS 
               #'min_samples_leaf':list(range(1,10)),
               #'min_samples_split': list(range(2,20)),
               'ccp_alpha':np.linspace(0,0.005,n), #UN RANGO DE ALPHA(PODA) CON N CORTES, AUNQUE PODIA SER UN N MAYOR A 10
               'max_depth':list(range(10,18))} #RANGO DE PROFUNDIDAD
                
#Cantidad de splits para el Cross Validation
folds=40 #IGUAL QUE EN EL DIBUJO CUANTAS CECES LO QUIERO PARTIR Y ENTRENAR

#Kfold estratificado
kfoldcv = StratifiedKFold(n_splits=folds) #5 FOLDS ESTRATIFICADOS RESPETE LA PROPORCION DE LA CLASE, EN LA MISMA PROPORCION ORIGINAL 

#Clasificador ARMO MI CLASIFICADOR 
base_tree = DecisionTreeClassifier() 

#Metrica que quiero optimizar F1 Score
scorer_fn = make_scorer(sk.metrics.f1_score) #ACA DECIDO QUE MI MEJOR CONJUNTO SEA A BSAE DE MEDIR F1 SCORE 

#Random Search Cross Validation BUSCADOR RANDOM CON VALIDACION CRUZADA
randomcv = RandomizedSearchCV(estimator=base_tree, #CREO MI VALIDACION CRUZADA con busqueda random de hiperparametros RANDOM SEARCH
                              param_distributions = params_grid,
                              scoring=scorer_fn, #METRICA QUE QUUIERO OPTIMIZAR
                              cv=kfoldcv,
                              n_iter=n) #LO TENER QUE HACER 10 VECES, PORQUE ES LA CANT DE HIPERPARAMETROS  

#Busco los hiperparamtros que optimizan F1 Score
randomcv.fit(x_train,y_train); #LO ENTRENO SOBRE MI DATASET DE ENTRENAMIENTO

#Mejores hiperparametros del arbol PROBASTE 10 DECIME CUAL FUE EL DE LA MEJOR METRICAS
print(randomcv.best_params_)
#Mejor métrica
print(randomcv.best_score_)

#Atributos considerados y su importancia
best_tree = randomcv.best_estimator_ #ME DEVUELVE MI MEJOR ARBOL
feat_imps = best_tree.feature_importances_ #AL MEJOR ARBOL LE PIDO SUS MEJORES FEATURES

for feat_imp,feat in sorted(zip(feat_imps,features4)): #ME DIJO CON EL ALCOHOL Y SULFATOS TE PUEDO ARMAR UN BUEN CLASIFICADOR (EL ALCOHOL TIENE BUENA CORRELACION CON EL TARGET LO VIMOS EN EL HEATMAP)
  if feat_imp>0:
    print('{}: {}'.format(feat,feat_imp))

#Creo el árbol con los mejores hiperparámetros
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_text

arbol4 =DecisionTreeClassifier().set_params(**randomcv.best_params_)

#Entreno el arbol en todo el set
arbol4.fit(x_train,y_train) #LO ENTRENO CON TODO EL SET DE ENTRENAMIENTO

reglas = export_text(arbol4, feature_names=list(features4)) #IMPRIMO TODAS LAS REGLAS
print(reglas)

y_pred = arbol4.predict(x_test)

accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
f1=f1_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)

print("Accuracy: "+str(accuracy)) 
print("Recall: "+str(recall))
print("Precision: "+str(precision))
print("f1 score: "+str(f1))

prueba4 = df_test[['lead_time', 'stays_in_weekend_nights',
       'stays_in_week_nights', 'adults', 'children', 'babies',
       'is_repeated_guest',
       'previous_cancellations', 'previous_bookings_not_canceled','booking_changes',
        'days_in_waiting_list',
       'average_daily_rate', 'required_car_parking_spaces',
       'total_of_special_requests', 'hotel_Resort Hotel',
       'meal_FB', 'meal_HB', 'meal_SC']]

predicciones4 = arbol4.predict(prueba4)

predicciones4

df_submission = pd.DataFrame({'id':df_test['id'], 'is_canceled':predicciones4})
df_submission.head()
df_submission.shape

#df_submission.to_csv('/content/submissions/submission_v4.csv', index=False)

joblib.dump(arbol4, 'arbol4.pkl')

"""# Arbol de decision N5"""

dataset.columns

features5= ['lead_time', 'stays_in_weekend_nights',
       'stays_in_week_nights', 'adults', 'children', 'babies',
       'is_repeated_guest',
       'previous_cancellations', 'previous_bookings_not_canceled','booking_changes',
        'days_in_waiting_list',
       'average_daily_rate', 'required_car_parking_spaces',
       'total_of_special_requests', 'hotel_Resort Hotel',
       'meal_FB', 'meal_HB', 'meal_SC','deposit_type_Non Refund', 'deposit_type_Refundable']

x_train, x_test, y_train, y_test = train_test_split(dataset[features5].values, 
                                                    dataset[target].values, 
                                                    test_size=0.2,    #20% al conjunto de test 80/20
                                                    random_state=13,  #para poder reproducir el experimento
                                                    stratify=dataset[target].values) #estratificado para mantener proporcion #QUEREMOS QUE SE RESPETE LA DIST DE LAS CLASES, APRENDER DE LAS 2 CLASES

#Verifico Cantidad de Datos en cada set
print('# Datos Entrenamiento: {}'.format(len(x_train)))
print('# Datos Prueba: {}'.format(len(x_test)))

#Verifico como quedaron balanceados
for split_name, split in zip(['% Positivos Entrenamiento','% Positivos Prueba'],[y_train,y_test]):
  print('{}: {:.3f}'.format(split_name,pd.Series(split).value_counts(normalize=True)[1]*100))

##KFOLD CV Random Search para buscar el mejor arbol (los mejores atributos, hiperparametros,etc)
from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import make_scorer

#Cantidad de combinaciones que quiero porbar
n=30 #LE PIDO QUE ME ARME 20 COMB POR CADA SPLIT(ENTRENA 20 ARBOLES POR CADA SPLIT)

#Conjunto de parámetros que quiero usar GRILLA DE PARAMETROS
params_grid = {'criterion':['gini','entropy'], #LE DOY POSIBLES CRITERIOS DE PARAMETROS 
               #'min_samples_leaf':list(range(1,10)),
               #'min_samples_split': list(range(2,20)),
               'ccp_alpha':np.linspace(0,0.005,n), #UN RANGO DE ALPHA(PODA) CON N CORTES, AUNQUE PODIA SER UN N MAYOR A 10
               'max_depth':list(range(10,22))} #RANGO DE PROFUNDIDAD
                
#Cantidad de splits para el Cross Validation
folds=40 #IGUAL QUE EN EL DIBUJO CUANTAS CECES LO QUIERO PARTIR Y ENTRENAR

#Kfold estratificado
kfoldcv = StratifiedKFold(n_splits=folds) #5 FOLDS ESTRATIFICADOS RESPETE LA PROPORCION DE LA CLASE, EN LA MISMA PROPORCION ORIGINAL 

#Clasificador ARMO MI CLASIFICADOR 
base_tree = DecisionTreeClassifier() 

#Metrica que quiero optimizar F1 Score
scorer_fn = make_scorer(sk.metrics.f1_score) #ACA DECIDO QUE MI MEJOR CONJUNTO SEA A BSAE DE MEDIR F1 SCORE 

#Random Search Cross Validation BUSCADOR RANDOM CON VALIDACION CRUZADA
randomcv = RandomizedSearchCV(estimator=base_tree, #CREO MI VALIDACION CRUZADA con busqueda random de hiperparametros RANDOM SEARCH
                              param_distributions = params_grid,
                              scoring=scorer_fn, #METRICA QUE QUUIERO OPTIMIZAR
                              cv=kfoldcv,
                              n_iter=n) #LO TENER QUE HACER 10 VECES, PORQUE ES LA CANT DE HIPERPARAMETROS  

#Busco los hiperparamtros que optimizan F1 Score
randomcv.fit(x_train,y_train); #LO ENTRENO SOBRE MI DATASET DE ENTRENAMIENTO

#Mejores hiperparametros del arbol PROBASTE 10 DECIME CUAL FUE EL DE LA MEJOR METRICAS
print(randomcv.best_params_)
#Mejor métrica
print(randomcv.best_score_) #0.7555114548598617 antes teniamos este con prfundidad 14

#Atributos considerados y su importancia
best_tree = randomcv.best_estimator_ #ME DEVUELVE MI MEJOR ARBOL
feat_imps = best_tree.feature_importances_ #AL MEJOR ARBOL LE PIDO SUS MEJORES FEATURES

for feat_imp,feat in sorted(zip(feat_imps,features5)): #ME DIJO CON EL ALCOHOL Y SULFATOS TE PUEDO ARMAR UN BUEN CLASIFICADOR (EL ALCOHOL TIENE BUENA CORRELACION CON EL TARGET LO VIMOS EN EL HEATMAP)
  if feat_imp>0:
    print('{}: {}'.format(feat,feat_imp))

#Creo el árbol con los mejores hiperparámetros
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_text

arbol5=DecisionTreeClassifier().set_params(**randomcv.best_params_)

#Entreno el arbol en todo el set
arbol5.fit(x_train,y_train) #LO ENTRENO CON TODO EL SET DE ENTRENAMIENTO

reglas = export_text(arbol5, feature_names=list(features5)) #IMPRIMO TODAS LAS REGLAS
print(reglas)

df_test.columns

y_pred = arbol5.predict(x_test)

accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
f1=f1_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)

print("Accuracy: "+str(accuracy)) 
print("Recall: "+str(recall))
print("Precision: "+str(precision))
print("f1 score: "+str(f1))

prueba5 = df_test[['lead_time', 'stays_in_weekend_nights',
       'stays_in_week_nights', 'adults', 'children', 'babies',
       'is_repeated_guest',
       'previous_cancellations', 'previous_bookings_not_canceled','booking_changes',
        'days_in_waiting_list',
       'average_daily_rate', 'required_car_parking_spaces',
       'total_of_special_requests', 'hotel_Resort Hotel',
       'meal_FB', 'meal_HB', 'meal_SC',
       'deposit_type_Non Refund', 'deposit_type_Refundable']]

predicciones5 = arbol5.predict(prueba5)

predicciones5

df_submission = pd.DataFrame({'id':df_test['id'], 'is_canceled':predicciones5})
df_submission.head()
df_submission.shape

#df_submission.to_csv('/content/drive/MyDrive/submissions/submission_v5.csv', index=False)

joblib.dump(arbol5, 'arbol5.pkl')

"""# Arbol de decision N6"""

dataset.columns

features6= ['deposit_type_Non Refund', 'lead_time','average_daily_rate','assigned_equals_reserved','previous_cancellations', 'required_car_parking_spaces', 'booking_changes','stays_in_week_nights','adults', 'hotel_Resort Hotel','total_of_special_requests']

x_train, x_test, y_train, y_test = train_test_split(dataset[features6].values, 
                                                    dataset[target].values, 
                                                    test_size=0.2,    #20% al conjunto de test 80/20
                                                    random_state=13,  #para poder reproducir el experimento
                                                    stratify=dataset[target].values) #estratificado para mantener proporcion #QUEREMOS QUE SE RESPETE LA DIST DE LAS CLASES, APRENDER DE LAS 2 CLASES

#Verifico Cantidad de Datos en cada set
print('# Datos Entrenamiento: {}'.format(len(x_train)))
print('# Datos Prueba: {}'.format(len(x_test)))

#Verifico como quedaron balanceados
for split_name, split in zip(['% Positivos Entrenamiento','% Positivos Prueba'],[y_train,y_test]):
  print('{}: {:.3f}'.format(split_name,pd.Series(split).value_counts(normalize=True)[1]*100))

##KFOLD CV Random Search para buscar el mejor arbol (los mejores atributos, hiperparametros,etc)
from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import make_scorer

#Cantidad de combinaciones que quiero porbar
n=30 #LE PIDO QUE ME ARME 20 COMB POR CADA SPLIT(ENTRENA 20 ARBOLES POR CADA SPLIT)

#Conjunto de parámetros que quiero usar GRILLA DE PARAMETROS
params_grid = {'criterion':['gini','entropy'], #LE DOY POSIBLES CRITERIOS DE PARAMETROS 
               #'min_samples_leaf':list(range(1,10)),
               #'min_samples_split': list(range(2,20)),
               'ccp_alpha':np.linspace(0,0.005,n), #UN RANGO DE ALPHA(PODA) CON N CORTES, AUNQUE PODIA SER UN N MAYOR A 10
               'max_depth':list(range(9,15))} #RANGO DE PROFUNDIDAD
                
#Cantidad de splits para el Cross Validation
folds=40 #IGUAL QUE EN EL DIBUJO CUANTAS CECES LO QUIERO PARTIR Y ENTRENAR

#Kfold estratificado
kfoldcv = StratifiedKFold(n_splits=folds) #5 FOLDS ESTRATIFICADOS RESPETE LA PROPORCION DE LA CLASE, EN LA MISMA PROPORCION ORIGINAL 

#Clasificador ARMO MI CLASIFICADOR 
base_tree = DecisionTreeClassifier() 

#Metrica que quiero optimizar F1 Score
scorer_fn = make_scorer(sk.metrics.f1_score) #ACA DECIDO QUE MI MEJOR CONJUNTO SEA A BSAE DE MEDIR F1 SCORE 

#Random Search Cross Validation BUSCADOR RANDOM CON VALIDACION CRUZADA
randomcv = RandomizedSearchCV(estimator=base_tree, #CREO MI VALIDACION CRUZADA con busqueda random de hiperparametros RANDOM SEARCH
                              param_distributions = params_grid,
                              scoring=scorer_fn, #METRICA QUE QUUIERO OPTIMIZAR
                              cv=kfoldcv,
                              n_iter=n) #LO TENER QUE HACER 10 VECES, PORQUE ES LA CANT DE HIPERPARAMETROS  

#Busco los hiperparamtros que optimizan F1 Score
randomcv.fit(x_train,y_train); #LO ENTRENO SOBRE MI DATASET DE ENTRENAMIENTO

#Mejores hiperparametros del arbol PROBASTE 10 DECIME CUAL FUE EL DE LA MEJOR METRICAS
print(randomcv.best_params_)
#Mejor métrica
print(randomcv.best_score_) #0.7555114548598617 antes teniamos este con prfundidad 14

#Atributos considerados y su importancia
best_tree = randomcv.best_estimator_ #ME DEVUELVE MI MEJOR ARBOL
feat_imps = best_tree.feature_importances_ #AL MEJOR ARBOL LE PIDO SUS MEJORES FEATURES

for feat_imp,feat in sorted(zip(feat_imps,features6)): #ME DIJO CON EL ALCOHOL Y SULFATOS TE PUEDO ARMAR UN BUEN CLASIFICADOR (EL ALCOHOL TIENE BUENA CORRELACION CON EL TARGET LO VIMOS EN EL HEATMAP)
  if feat_imp>0:
    print('{}: {}'.format(feat,feat_imp))

#Creo el árbol con los mejores hiperparámetros
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_text

arbol6=DecisionTreeClassifier().set_params(**randomcv.best_params_)

#Entreno el arbol en todo el set
arbol6.fit(x_train,y_train) #LO ENTRENO CON TODO EL SET DE ENTRENAMIENTO

reglas = export_text(arbol6, feature_names=list(features6)) #IMPRIMO TODAS LAS REGLAS
print(reglas)

y_pred = arbol6.predict(x_test)

accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
f1=f1_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)

print("Accuracy: "+str(accuracy)) 
print("Recall: "+str(recall))
print("Precision: "+str(precision))
print("f1 score: "+str(f1))

prueba6 = df_test[['deposit_type_Non Refund', 'lead_time','average_daily_rate','assigned_equals_reserved','previous_cancellations', 'required_car_parking_spaces', 'booking_changes','stays_in_week_nights','adults', 'hotel_Resort Hotel','total_of_special_requests']]

predicciones6 = arbol6.predict(prueba6)

from six import StringIO #IMPRIMO EL ARBOL
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
import matplotlib.pyplot as plt

dot_data = StringIO()
export_graphviz(arbol6, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True,
                feature_names=features6,
                class_names=['good','bad'])

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png())

df_submission = pd.DataFrame({'id':df_test['id'], 'is_canceled':predicciones6})
df_submission.head()
df_submission.shape

#df_submission.to_csv('/content/drive/MyDrive/submissions/submission_v6.csv', index=False)

joblib.dump(arbol6, 'arbol6.pkl')

"""#Arbol de decision N7"""

features7= ['lead_time', 'stays_in_weekend_nights',
       'stays_in_week_nights', 'adults', 'children', 'babies',
       'is_repeated_guest',
       'previous_cancellations', 'previous_bookings_not_canceled','booking_changes',
        'days_in_waiting_list',
       'average_daily_rate', 'required_car_parking_spaces',
       'total_of_special_requests', 'hotel_Resort Hotel',
       'meal_FB', 'meal_HB', 'meal_SC',
       'deposit_type_Non Refund', 'deposit_type_Refundable','assigned_equals_reserved']

x_train, x_test, y_train, y_test = train_test_split(dataset[features7].values, 
                                                    dataset[target].values, 
                                                    test_size=0.2,    #20% al conjunto de test 80/20
                                                    random_state=13,  #para poder reproducir el experimento
                                                    stratify=dataset[target].values) #estratificado para mantener proporcion #QUEREMOS QUE SE RESPETE LA DIST DE LAS CLASES, APRENDER DE LAS 2 CLASES

#Verifico Cantidad de Datos en cada set
print('# Datos Entrenamiento: {}'.format(len(x_train)))
print('# Datos Prueba: {}'.format(len(x_test)))

#Verifico como quedaron balanceados
for split_name, split in zip(['% Positivos Entrenamiento','% Positivos Prueba'],[y_train,y_test]):
  print('{}: {:.3f}'.format(split_name,pd.Series(split).value_counts(normalize=True)[1]*100))

##KFOLD CV Random Search para buscar el mejor arbol (los mejores atributos, hiperparametros,etc)
from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import make_scorer

#Cantidad de combinaciones que quiero porbar
n=30 #LE PIDO QUE ME ARME 20 COMB POR CADA SPLIT(ENTRENA 20 ARBOLES POR CADA SPLIT)

#Conjunto de parámetros que quiero usar GRILLA DE PARAMETROS
params_grid = {'criterion':['gini','entropy'], #LE DOY POSIBLES CRITERIOS DE PARAMETROS 
               #'min_samples_leaf':list(range(1,10)),
               #'min_samples_split': list(range(2,20)),
               'ccp_alpha':np.linspace(0,0.005,n), #UN RANGO DE ALPHA(PODA) CON N CORTES, AUNQUE PODIA SER UN N MAYOR A 10
               'max_depth':list(range(9,15))} #RANGO DE PROFUNDIDAD
                
#Cantidad de splits para el Cross Validation
folds=40 #IGUAL QUE EN EL DIBUJO CUANTAS CECES LO QUIERO PARTIR Y ENTRENAR

#Kfold estratificado
kfoldcv = StratifiedKFold(n_splits=folds) #5 FOLDS ESTRATIFICADOS RESPETE LA PROPORCION DE LA CLASE, EN LA MISMA PROPORCION ORIGINAL 

#Clasificador ARMO MI CLASIFICADOR 
base_tree = DecisionTreeClassifier() 

#Metrica que quiero optimizar F1 Score
scorer_fn = make_scorer(sk.metrics.f1_score) #ACA DECIDO QUE MI MEJOR CONJUNTO SEA A BSAE DE MEDIR F1 SCORE 

#Random Search Cross Validation BUSCADOR RANDOM CON VALIDACION CRUZADA
randomcv = RandomizedSearchCV(estimator=base_tree, #CREO MI VALIDACION CRUZADA con busqueda random de hiperparametros RANDOM SEARCH
                              param_distributions = params_grid,
                              scoring=scorer_fn, #METRICA QUE QUUIERO OPTIMIZAR
                              cv=kfoldcv,
                              n_iter=n) #LO TENER QUE HACER 10 VECES, PORQUE ES LA CANT DE HIPERPARAMETROS  

#Busco los hiperparamtros que optimizan F1 Score
randomcv.fit(x_train,y_train); #LO ENTRENO SOBRE MI DATASET DE ENTRENAMIENTO

#Mejores hiperparametros del arbol
print(randomcv.best_params_)
#Mejor métrica
print(randomcv.best_score_)

#Atributos considerados y su importancia
best_tree = randomcv.best_estimator_ #ME DEVUELVE MI MEJOR ARBOL
feat_imps = best_tree.feature_importances_ #AL MEJOR ARBOL LE PIDO SUS MEJORES FEATURES

for feat_imp,feat in sorted(zip(feat_imps,features7)): 
  if feat_imp>0:
    print('{}: {}'.format(feat,feat_imp))

#Creo el árbol con los mejores hiperparámetros
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_text

arbol7=DecisionTreeClassifier().set_params(**randomcv.best_params_)

#Entreno el arbol en todo el set
arbol7.fit(x_train,y_train) #LO ENTRENO CON TODO EL SET DE ENTRENAMIENTO

reglas = export_text(arbol7, feature_names=list(features7)) #IMPRIMO TODAS LAS REGLAS
print(reglas)

y_pred = arbol7.predict(x_test)

accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
f1=f1_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)

print("Accuracy: "+str(accuracy)) 
print("Recall: "+str(recall))
print("Precision: "+str(precision))
print("f1 score: "+str(f1))

prueba7 = df_test[['lead_time', 'stays_in_weekend_nights',
       'stays_in_week_nights', 'adults', 'children', 'babies',
       'is_repeated_guest',
       'previous_cancellations', 'previous_bookings_not_canceled','booking_changes',
        'days_in_waiting_list',
       'average_daily_rate', 'required_car_parking_spaces',
       'total_of_special_requests', 'hotel_Resort Hotel',
       'meal_FB', 'meal_HB', 'meal_SC',
       'deposit_type_Non Refund', 'deposit_type_Refundable','assigned_equals_reserved']]

predicciones7 = arbol7.predict(prueba7)

from six import StringIO #IMPRIMO EL ARBOL
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
import matplotlib.pyplot as plt

dot_data = StringIO()
export_graphviz(arbol7, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True,
                feature_names=features7,
                class_names=['good','bad'])

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png())

df_submission = pd.DataFrame({'id':df_test['id'], 'is_canceled':predicciones7})
df_submission.head()
df_submission.shape

#df_submission.to_csv('/content/drive/MyDrive/submissions/submission_v7.csv', index=False)

joblib.dump(arbol7, 'arbol7.pkl')

"""#Arbol de decision N8"""

features8=['lead_time',
       'stays_in_week_nights', 'adults',
       'previous_cancellations', 'previous_bookings_not_canceled','booking_changes',
        'days_in_waiting_list',
       'average_daily_rate', 'required_car_parking_spaces',
       'total_of_special_requests', 'hotel_Resort Hotel',
       'deposit_type_Non Refund','assigned_equals_reserved', 'temporada_alta']

x_train, x_test, y_train, y_test = train_test_split(dataset[features8].values, 
                                                    dataset[target].values, 
                                                    test_size=0.2,    #20% al conjunto de test 80/20
                                                    random_state=13,  #para poder reproducir el experimento
                                                    stratify=dataset[target].values) #estratificado para mantener proporcion #QUEREMOS QUE SE RESPETE LA DIST DE LAS CLASES, APRENDER DE LAS 2 CLASES

#Verifico Cantidad de Datos en cada set
print('# Datos Entrenamiento: {}'.format(len(x_train)))
print('# Datos Prueba: {}'.format(len(x_test)))

#Verifico como quedaron balanceados
for split_name, split in zip(['% Positivos Entrenamiento','% Positivos Prueba'],[y_train,y_test]):
  print('{}: {:.3f}'.format(split_name,pd.Series(split).value_counts(normalize=True)[1]*100))

##KFOLD CV Random Search para buscar el mejor arbol (los mejores atributos, hiperparametros,etc)
from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import make_scorer

#Cantidad de combinaciones que quiero porbar
n=30 #LE PIDO QUE ME ARME 20 COMB POR CADA SPLIT(ENTRENA 20 ARBOLES POR CADA SPLIT)

#Conjunto de parámetros que quiero usar GRILLA DE PARAMETROS
params_grid = {'criterion':['gini','entropy'], #LE DOY POSIBLES CRITERIOS DE PARAMETROS 
               #'min_samples_leaf':list(range(1,10)),
               #'min_samples_split': list(range(2,20)),
               'ccp_alpha':np.linspace(0,0.005,n), #UN RANGO DE ALPHA(PODA) CON N CORTES, AUNQUE PODIA SER UN N MAYOR A 10
               'max_depth':list(range(9,15))} #RANGO DE PROFUNDIDAD
                
#Cantidad de splits para el Cross Validation
folds=40 #IGUAL QUE EN EL DIBUJO CUANTAS CECES LO QUIERO PARTIR Y ENTRENAR

#Kfold estratificado
kfoldcv = StratifiedKFold(n_splits=folds) #5 FOLDS ESTRATIFICADOS RESPETE LA PROPORCION DE LA CLASE, EN LA MISMA PROPORCION ORIGINAL 

#Clasificador ARMO MI CLASIFICADOR 
base_tree = DecisionTreeClassifier() 

#Metrica que quiero optimizar F1 Score
scorer_fn = make_scorer(sk.metrics.f1_score) #ACA DECIDO QUE MI MEJOR CONJUNTO SEA A BSAE DE MEDIR F1 SCORE 

#Random Search Cross Validation BUSCADOR RANDOM CON VALIDACION CRUZADA
randomcv = RandomizedSearchCV(estimator=base_tree, #CREO MI VALIDACION CRUZADA con busqueda random de hiperparametros RANDOM SEARCH
                              param_distributions = params_grid,
                              scoring=scorer_fn, #METRICA QUE QUUIERO OPTIMIZAR
                              cv=kfoldcv,
                              n_iter=n) #LO TENER QUE HACER 10 VECES, PORQUE ES LA CANT DE HIPERPARAMETROS  

#Busco los hiperparamtros que optimizan F1 Score
randomcv.fit(x_train,y_train); #LO ENTRENO SOBRE MI DATASET DE ENTRENAMIENTO

#Mejores hiperparametros del arbol PROBASTE 10 DECIME CUAL FUE EL DE LA MEJOR METRICAS
print(randomcv.best_params_)
#Mejor métrica
print(randomcv.best_score_) #0.7555114548598617 antes teniamos este con prfundidad 14

#Atributos considerados y su importancia
best_tree = randomcv.best_estimator_ #ME DEVUELVE MI MEJOR ARBOL
feat_imps = best_tree.feature_importances_ #AL MEJOR ARBOL LE PIDO SUS MEJORES FEATURES

for feat_imp,feat in sorted(zip(feat_imps,features8)): #ME DIJO CON EL ALCOHOL Y SULFATOS TE PUEDO ARMAR UN BUEN CLASIFICADOR (EL ALCOHOL TIENE BUENA CORRELACION CON EL TARGET LO VIMOS EN EL HEATMAP)
  if feat_imp>0:
    print('{}: {}'.format(feat,feat_imp))

#Creo el árbol con los mejores hiperparámetros
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_text

arbol8=DecisionTreeClassifier().set_params(**randomcv.best_params_)

#Entreno el arbol en todo el set
arbol8.fit(x_train,y_train) #LO ENTRENO CON TODO EL SET DE ENTRENAMIENTO

reglas = export_text(arbol8, feature_names=list(features8)) #IMPRIMO TODAS LAS REGLAS
print(reglas)

y_pred = arbol8.predict(x_test)

accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
f1=f1_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)

print("Accuracy: "+str(accuracy)) 
print("Recall: "+str(recall))
print("Precision: "+str(precision))
print("f1 score: "+str(f1))

prueba8 = df_test[['lead_time',
       'stays_in_week_nights', 'adults',
       'previous_cancellations', 'previous_bookings_not_canceled','booking_changes',
        'days_in_waiting_list',
       'average_daily_rate', 'required_car_parking_spaces',
       'total_of_special_requests', 'hotel_Resort Hotel',
       'deposit_type_Non Refund','assigned_equals_reserved', 'temporada_alta']]

predicciones8 = arbol8.predict(prueba8)

from six import StringIO #IMPRIMO EL ARBOL
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
import matplotlib.pyplot as plt

dot_data = StringIO()
export_graphviz(arbol8, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True,
                feature_names=features8,
                class_names=['good','bad'])

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png())

df_submission = pd.DataFrame({'id':df_test['id'], 'is_canceled':predicciones8})
df_submission.head()
df_submission.shape

#df_submission.to_csv('/content/drive/MyDrive/submissions/submission_v8.csv', index=False)

joblib.dump(arbol8, 'arbol8.pkl')

"""#Arbol de decision N9"""

dataset.columns

features9= ['deposit_type_Non Refund','lead_time','average_daily_rate','assigned_equals_reserved','previous_cancellations', 
'required_car_parking_spaces','booking_changes','stays_in_week_nights','adults','hotel_Resort Hotel','total_of_special_requests',
'customer_type_Group', 'customer_type_Transient','customer_type_Transient-Party','country_PRT', 'country_GBR',
'country_FRA','country_ESP','country_DEU', 'distribution_channel_TA/TO','market_segment_Offline TA/TO', 'market_segment_Online TA']

x_train, x_test, y_train, y_test = train_test_split(dataset[features9].values, 
                                                    dataset[target].values, 
                                                    test_size=0.2,    #20% al conjunto de test 80/20
                                                    random_state=13,  #para poder reproducir el experimento
                                                    stratify=dataset[target].values) #estratificado para mantener proporcion #QUEREMOS QUE SE RESPETE LA DIST DE LAS CLASES, APRENDER DE LAS 2 CLASES

#Verifico Cantidad de Datos en cada set
print('# Datos Entrenamiento: {}'.format(len(x_train)))
print('# Datos Prueba: {}'.format(len(x_test)))

#Verifico como quedaron balanceados
for split_name, split in zip(['% Positivos Entrenamiento','% Positivos Prueba'],[y_train,y_test]):
  print('{}: {:.3f}'.format(split_name,pd.Series(split).value_counts(normalize=True)[1]*100))

##KFOLD CV Random Search para buscar el mejor arbol (los mejores atributos, hiperparametros,etc)
from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import make_scorer

#Cantidad de combinaciones que quiero porbar
n=30 #LE PIDO QUE ME ARME 20 COMB POR CADA SPLIT(ENTRENA 20 ARBOLES POR CADA SPLIT)

#Conjunto de parámetros que quiero usar GRILLA DE PARAMETROS
params_grid = {'criterion':['gini','entropy'], #LE DOY POSIBLES CRITERIOS DE PARAMETROS 
               #'min_samples_leaf':list(range(1,10)),
               #'min_samples_split': list(range(2,20)),
               'ccp_alpha':np.linspace(0.001,0.005,n), #UN RANGO DE ALPHA(PODA) CON N CORTES, AUNQUE PODIA SER UN N MAYOR A 10
               'max_depth':list(range(15,24))} #RANGO DE PROFUNDIDAD
                
#Cantidad de splits para el Cross Validation
folds=40 #IGUAL QUE EN EL DIBUJO CUANTAS CECES LO QUIERO PARTIR Y ENTRENAR

#Kfold estratificado
kfoldcv = StratifiedKFold(n_splits=folds) #5 FOLDS ESTRATIFICADOS RESPETE LA PROPORCION DE LA CLASE, EN LA MISMA PROPORCION ORIGINAL 

#Clasificador ARMO MI CLASIFICADOR 
base_tree = DecisionTreeClassifier() 

#Metrica que quiero optimizar F1 Score
scorer_fn = make_scorer(sk.metrics.f1_score) #ACA DECIDO QUE MI MEJOR CONJUNTO SEA A BSAE DE MEDIR F1 SCORE 

#Random Search Cross Validation BUSCADOR RANDOM CON VALIDACION CRUZADA
randomcv = RandomizedSearchCV(estimator=base_tree, #CREO MI VALIDACION CRUZADA con busqueda random de hiperparametros RANDOM SEARCH
                              param_distributions = params_grid,
                              scoring=scorer_fn, #METRICA QUE QUUIERO OPTIMIZAR
                              cv=kfoldcv,
                              n_iter=n) #LO TENER QUE HACER 10 VECES, PORQUE ES LA CANT DE HIPERPARAMETROS  

#Busco los hiperparamtros que optimizan F1 Score
randomcv.fit(x_train,y_train); #LO ENTRENO SOBRE MI DATASET DE ENTRENAMIENTO

#Mejores hiperparametros del arbol 
print(randomcv.best_params_)
#Mejor métrica
print(randomcv.best_score_)

#Atributos considerados y su importancia
best_tree = randomcv.best_estimator_ #ME DEVUELVE MI MEJOR ARBOL
feat_imps = best_tree.feature_importances_ #AL MEJOR ARBOL LE PIDO SUS MEJORES FEATURES

for feat_imp,feat in sorted(zip(feat_imps,features9)): 
  if feat_imp>0:
    print('{}: {}'.format(feat,feat_imp))

#Creo el árbol con los mejores hiperparámetros
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_text

arbol9=DecisionTreeClassifier().set_params(**randomcv.best_params_)

#Entreno el arbol en todo el set
arbol9.fit(x_train,y_train) #LO ENTRENO CON TODO EL SET DE ENTRENAMIENTO

reglas = export_text(arbol9, feature_names=list(features9)) #IMPRIMO TODAS LAS REGLAS
print(reglas)

y_pred = arbol9.predict(x_test)

accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
f1=f1_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)

print("Accuracy: "+str(accuracy)) 
print("Recall: "+str(recall))
print("Precision: "+str(precision))
print("f1 score: "+str(f1))

prueba9 = df_test[['deposit_type_Non Refund', 'lead_time','average_daily_rate','assigned_equals_reserved','previous_cancellations', 'required_car_parking_spaces', 'booking_changes','stays_in_week_nights','adults', 'hotel_Resort Hotel','total_of_special_requests','customer_type_Group', 'customer_type_Transient',
       'customer_type_Transient-Party','country_PRT', 'country_GBR','country_FRA','country_ESP','country_DEU', 'distribution_channel_TA/TO','market_segment_Offline TA/TO', 'market_segment_Online TA']]

predicciones9 = arbol9.predict(prueba9)

from six import StringIO #IMPRIMO EL ARBOL
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
import matplotlib.pyplot as plt

dot_data = StringIO()
export_graphviz(arbol9, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True,
                feature_names=features9,
                class_names=['good','bad'])

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png())

df_submission = pd.DataFrame({'id':df_test['id'], 'is_canceled':predicciones9})
df_submission.head()
df_submission.shape

#df_submission.to_csv('/content/drive/MyDrive/submissions/submission_v10.csv', index=False)

"""# Matriz de Confusion"""

y_pred = arbol9.predict(x_test)

#Creo la matriz de confusión
tabla=confusion_matrix(y_test, y_pred)

#Grafico la matriz de confusión
sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')

"""# Performance"""

accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
f1=f1_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)

print("Accuracy: "+str(accuracy)) 
print("Recall: "+str(recall))
print("Precision: "+str(precision))
print("f1 score: "+str(f1))

joblib.dump(arbol9, 'arbol9.pkl')